#!/bin/bash
#SBATCH --job-name=cttick_pipeline
#SBATCH --output=logs/cttick_%A_%a.out
#SBATCH --error=logs/cttick_%A_%a.err
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --time=02:00:00
#SBATCH --array=1-5  # Number of scans in batch (will be updated by FastAPI)

# This is a template - the actual script will be generated by FastAPI
# with specific scan IDs and job ID

# Load modules
module load anaconda3

# Activate environment
source activate tickml

# Set environment variables
export FIREBASE_CREDENTIALS_PATH=~/MorphoVue/ml-pipeline/firebase-key.json
export FIREBASE_STORAGE_BUCKET=your-project-id.appspot.com
export YOLO_WEIGHTS=~/MorphoVue/ml-pipeline/weights/yolov10s.pt
export MONAI_WEIGHTS=~/MorphoVue/ml-pipeline/weights/monai_unet.pth

# Array of scan IDs (will be populated by FastAPI)
SCAN_IDS=(scan_id_1 scan_id_2 scan_id_3)

# Get scan ID for this array task
SCAN_ID=${SCAN_IDS[$SLURM_ARRAY_TASK_ID-1]}

# Job ID for Firebase tracking (will be set by FastAPI)
JOB_ID="job_id_placeholder"

echo "=========================================="
echo "CT Tick ML Pipeline"
echo "=========================================="
echo "Job ID: $SLURM_JOB_ID"
echo "Array Task ID: $SLURM_ARRAY_TASK_ID"
echo "Scan ID: $SCAN_ID"
echo "Tracking Job ID: $JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Start time: $(date)"
echo "=========================================="

# Change to pipeline directory
cd ~/MorphoVue/ml-pipeline

# Run the ML pipeline
python3 run_yolo10_monai.py $SCAN_ID $JOB_ID

# Check exit status
if [ $? -eq 0 ]; then
    echo "=========================================="
    echo "SUCCESS: Scan $SCAN_ID processed"
    echo "End time: $(date)"
    echo "=========================================="
else
    echo "=========================================="
    echo "ERROR: Scan $SCAN_ID processing failed"
    echo "End time: $(date)"
    echo "=========================================="
    exit 1
fi

